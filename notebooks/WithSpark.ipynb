{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load as yaml_load\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as func\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Data cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_config_file(config_file):\n",
    "    \"\"\"\n",
    "    Load configuration file\n",
    "    :param config_file: is the configuration file\n",
    "    :return: configuration\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    with open(config_file) as yml_config:\n",
    "        return yaml_load(yml_config)\n",
    "\n",
    "def _build_configuration(config_file):\n",
    "    \"\"\"\n",
    "    Build the operation configuration dict\n",
    "    :param config_file: is the path to the yaml config_file\n",
    "    :type: string\n",
    "    :return: config: global configuration\n",
    "    :rtype dict\n",
    "    \"\"\"\n",
    "    # yaml config\n",
    "    config = _load_config_file(config_file)\n",
    "    return config\n",
    "\n",
    "def normalize(df, columns):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    aggExpr = []\n",
    "    for column in columns:\n",
    "        aggExpr.append(mean(df[column]).alias(column))\n",
    "    averages = df.agg(*aggExpr).collect()[0]\n",
    "    selectExpr = []\n",
    "    for column in columns:\n",
    "        selectExpr.append(df[column] - averages[column])\n",
    "    return df.select(selectExpr)\n",
    "\n",
    "def get_dummies(df, list_columns):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def join_all(dfs, keys):\n",
    "        if len(dfs) > 1:\n",
    "            return dfs[0].join(join_all(dfs[1:], keys), on = keys, how = 'inner')\n",
    "        else:\n",
    "            return dfs[0]\n",
    "    dfs = []\n",
    "    combined = []\n",
    "    pivot_cols = list_columns\n",
    "    keys = df.columns\n",
    "    \n",
    "    for pivot_col in pivot_cols:\n",
    "        pivotDF =  df.groupBy(keys).pivot(pivot_col).count()\n",
    "        new_names = pivotDF.columns[:len(keys)] +  [\"{0}_{1}\".format(pivot_col, c)\\\n",
    "                                                for c in pivotDF.columns[len(keys):]] \n",
    "        df = pivotDF.toDF(*new_names).fillna(0)\n",
    "        combined.append(df)\n",
    "    df_result =  join_all(combined, keys)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/ml/Documents/crimes_chigaco/config/config.yml\"\n",
    "config = _build_configuration(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_crime():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return config['connect']['PathCrimes']\n",
    "\n",
    "def path_socio():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return config['connect']['PathSocioEco']\n",
    "\n",
    "def path_columns():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return config['connect']['Pathcolumns']\n",
    "\n",
    "def path_temperature():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    return config['connect']['PathTemperature']\n",
    "\n",
    "def path_sky():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return config['connect']['PathSky']\n",
    "def spark_shape(self):\n",
    "    return (self.count(), len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = json.loads(open(path_columns()).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_crime():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    column_name = json.loads(open(path_columns()).read())\n",
    "    df_crimes = spark.read.format(\"csv\").option(\"header\",\"true\").\\\n",
    "    option(\"mode\",\"DROPMALFORMED\").option(\"delimiter\", \";\").load(path_crime())\n",
    "    for old_name, new_name in column_name['DataCrimes'].items():\n",
    "        df_crimes = df_crimes.withColumnRenamed(old_name, new_name)\n",
    "    df_crimes = df_crimes.withColumn(\"date\", func.to_timestamp(\"date\", \"MM/dd/yyyy hh:mm:ss aaa\"))\n",
    "    \n",
    "    if config[\"List_of_crimes_prediction\"][\"with_merge\"]:\n",
    "        df_crimes = df_crimes.na.replace(config[\"List_of_crimes_prediction\"][\"to_merge\"],'primary_type')\n",
    "        return df_crimes\n",
    "\n",
    "    else:\n",
    "        return df_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_socio():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    column_name = json.loads(open(path_columns()).read())\n",
    "    df_socio = spark.read.format(\"csv\").option(\"header\",\"true\").\\\n",
    "    option(\"mode\",\"DROPMALFORMED\").option(\"delimiter\", \",\").load(path_socio())\n",
    "    \n",
    "    for old_name, new_name in column_name['SocioEco'].items():\n",
    "        df_socio = df_socio.withColumnRenamed(old_name, new_name)\n",
    "        \n",
    "    column_names_to_normalize = ['pct_housing_crowded','pct_households_below_poverty',  'pct_age16_unemployed' , 'pct_age25_no_highschool', 'pct_not_working_age','per_capita_income',\n",
    "                'hardship_index']\n",
    "\n",
    "    return df_socio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merged_spark():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    column_name = json.loads(open(self.path_columns()).read())\n",
    "    df_crime = pd.read_csv(self.path_crime(), sep=';')\n",
    "    df_crime.rename(columns=column_name['DataCrimes'], inplace=True)\n",
    "    df_socio = self.df_socio()\n",
    "    df_merged = pd.merge(df_crime, df_socio, on='community_area_number', how = 'left')\n",
    "   \n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_nb_crimes_spark():\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df_S = df_socio()\n",
    "    df_C = df_crime()\n",
    "    df_C = df_C.filter(func.col('primary_type').isin(config['NameCrime']))\n",
    "    name_crimes = df_crime_.select(\"primary_type\").distinct().collect()\n",
    "    list_name_crimes = [name_crimes[i][0] for i in range(len(name_crimes))]\n",
    "    df_year = df_C.filter((func.col('date') > '2015-03-18') & (func.col('date') < '2017-01-15'))\n",
    "    df_m  = df_year.withColumn(\"month\", func.month(func.col(\"date\"))).withColumn(\"year\", func.year(func.col(\"date\")))\n",
    "    df_nb_crimes = df_m.groupBy('community_area_number', 'month', 'year', 'primary_type').agg(func.count(df_m.id).alias('nb_crimes'))\n",
    "    df_merged = df_nb_crimes.join(df_S, ['community_area_number'], \"inner\")\n",
    "    df_result = get_dummies(df_merged , list_columns=['primary_type', 'community_area_name', 'month'])\n",
    "    del df_merged\n",
    "    del df_nb_crimes\n",
    "    del df_m\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py:1793: UserWarning: to_replace is a dict and value is not None. value will be ignored.\n",
      "  warnings.warn(\"to_replace is a dict and value is not None. value will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.4 ms, sys: 4.14 ms, total: 79.5 ms\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_nb_crimes_spark_ = df_nb_crimes_spark()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_temperature_spark():\n",
    "    \n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # pd.options.mode.chained_assignment = None\n",
    "    df = spark.read.format(\"csv\").option(\"header\",\"true\").\\\n",
    "    option(\"mode\",\"DROPMALFORMED\").option(\"delimiter\", \",\").load(path_temperature())\n",
    "    df = df.select('Chicago', 'datetime').withColumnRenamed('Chicago','Temperature')\n",
    "    df = df.filter((func.col('datetime') > '2017-05-10') & (func.col('datetime') < '2017-05-15'))\n",
    "    df = df.withColumn(\"month\", func.month(func.col(\"datetime\"))).\\\n",
    "    withColumn(\"year\", func.year(func.col(\"datetime\"))).withColumn(\"day\", func.dayofmonth(func.col(\"datetime\"))).\\\n",
    "    withColumn(\"hour\", func.hour(func.col(\"datetime\")))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temperature_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sky():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    df = spark.read.format(\"csv\").option(\"header\",\"true\").\\\n",
    "    option(\"mode\",\"DROPMALFORMED\").option(\"delimiter\", \",\").load(path_sky())\n",
    "    df = df.select('Chicago', 'datetime')\n",
    "    df= df.filter((func.col('datetime') > '2017-05-10') & (func.col('datetime') < '2017-05-15'))\n",
    "    df = get_dummies(df, list_columns=['Chicago'])\n",
    "    df= df.withColumn(\"month\", func.month(func.col(\"datetime\"))).\\\n",
    "    withColumn(\"year\", func.year(func.col(\"datetime\"))).withColumn(\"day\", func.dayofmonth(func.col(\"datetime\"))).\\\n",
    "    withColumn(\"hour\", func.hour(func.col(\"datetime\")))\n",
    "  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sky_ = df_sky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chicago</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Chicago_broken clouds</th>\n",
       "      <th>Chicago_few clouds</th>\n",
       "      <th>Chicago_fog</th>\n",
       "      <th>Chicago_haze</th>\n",
       "      <th>Chicago_heavy intensity rain</th>\n",
       "      <th>Chicago_light rain</th>\n",
       "      <th>Chicago_mist</th>\n",
       "      <th>Chicago_overcast clouds</th>\n",
       "      <th>Chicago_scattered clouds</th>\n",
       "      <th>Chicago_sky is clear</th>\n",
       "      <th>Chicago_thunderstorm</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2017-05-10 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>2017-05-11 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2017-05-10 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mist</td>\n",
       "      <td>2017-05-11 05:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2017-05-12 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Chicago             datetime  Chicago_broken clouds  \\\n",
       "68        overcast clouds  2017-05-10 09:00:00                      0   \n",
       "54   heavy intensity rain  2017-05-11 02:00:00                      0   \n",
       "108       overcast clouds  2017-05-10 06:00:00                      0   \n",
       "47                   mist  2017-05-11 05:00:00                      0   \n",
       "94           sky is clear  2017-05-12 04:00:00                      0   \n",
       "\n",
       "     Chicago_few clouds  Chicago_fog  Chicago_haze  \\\n",
       "68                    0            0             0   \n",
       "54                    0            0             0   \n",
       "108                   0            0             0   \n",
       "47                    0            0             0   \n",
       "94                    0            0             0   \n",
       "\n",
       "     Chicago_heavy intensity rain  Chicago_light rain  Chicago_mist  \\\n",
       "68                              0                   0             0   \n",
       "54                              1                   0             0   \n",
       "108                             0                   0             0   \n",
       "47                              0                   0             1   \n",
       "94                              0                   0             0   \n",
       "\n",
       "     Chicago_overcast clouds  Chicago_scattered clouds  Chicago_sky is clear  \\\n",
       "68                         1                         0                     0   \n",
       "54                         0                         0                     0   \n",
       "108                        1                         0                     0   \n",
       "47                         0                         0                     0   \n",
       "94                         0                         0                     1   \n",
       "\n",
       "     Chicago_thunderstorm  month  year  day  hour  \n",
       "68                      0      5  2017   10     9  \n",
       "54                      0      5  2017   11     2  \n",
       "108                     0      5  2017   10     6  \n",
       "47                      0      5  2017   11     5  \n",
       "94                      0      5  2017   12     4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sky_.toPandas().sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>datetime</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>290.91</td>\n",
       "      <td>2017-05-14 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>283.25</td>\n",
       "      <td>2017-05-11 12:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>287.12</td>\n",
       "      <td>2017-05-14 13:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>291.33</td>\n",
       "      <td>2017-05-12 17:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>281.74</td>\n",
       "      <td>2017-05-13 09:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature             datetime  month  year  day  hour\n",
       "111      290.91  2017-05-14 15:00:00      5  2017   14    15\n",
       "36       283.25  2017-05-11 12:00:00      5  2017   11    12\n",
       "109      287.12  2017-05-14 13:00:00      5  2017   14    13\n",
       "65       291.33  2017-05-12 17:00:00      5  2017   12    17\n",
       "81       281.74  2017-05-13 09:00:00      5  2017   13     9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.toPandas().sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataframe:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "\n",
    "        :param config:\n",
    "        \"\"\"\n",
    "        self._config = config\n",
    "     \n",
    "\n",
    "    def path_crime(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._config['connect']['PathCrimes']\n",
    "\n",
    "    def path_socio(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._config['connect']['PathSocioEco']\n",
    "\n",
    "    def path_columns(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._config['connect']['Pathcolumns']\n",
    "\n",
    "    def path_temperature(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return self._config['connect']['PathTemperature']\n",
    "\n",
    "    def path_sky(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._config['connect']['PathSky']\n",
    "\n",
    "    def df_crime(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        column_name = json.loads(open(path_columns()).read())\n",
    "        df_crime = pd.read_csv(self.path_crime(), sep=';', parse_dates=['Date'])\n",
    "        df_crime.rename(columns=column_name['DataCrimes'], inplace=True)\n",
    "\n",
    "        if self._config[\"List_of_crimes_prediction\"][\"with_merge\"]:\n",
    "            df_crime.replace({'primary_type': self._config[\"List_of_crimes_prediction\"][\"to_merge\"]}, inplace=True)\n",
    "            return df_crime\n",
    "\n",
    "        else:\n",
    "            return df_crime\n",
    "\n",
    "    def df_socio(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        column_name = json.loads(open(self.path_columns()).read())\n",
    "        df_socio = pd.read_csv(self.path_socio())\n",
    "        df_socio.rename(columns=column_name['SocioEco'], inplace=True)\n",
    "        column_names_to_normalize = ['pct_housing_crowded','pct_households_below_poverty',  'pct_age16_unemployed' , 'pct_age25_no_highschool', 'pct_not_working_age','per_capita_income',\n",
    "                'hardship_index']\n",
    "        x = df_socio[column_names_to_normalize].values\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index=df_socio.index)\n",
    "        df_socio[column_names_to_normalize] = df_temp\n",
    "        return df_socio\n",
    "\n",
    "    def df_crime_socio(self):\n",
    "        column_name = json.loads(open(self.path_columns()).read())\n",
    "        df_crime = pd.read_csv(self.path_crime(), sep=';')\n",
    "        df_crime.rename(columns=column_name['DataCrimes'], inplace=True)\n",
    "        df_socio = self.df_socio()\n",
    "        df_merged = pd.merge(df_crime, df_socio, on='community_area_number', how='left')\n",
    "        return df_merged\n",
    "\n",
    "    def df_temperature(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pd.options.mode.chained_assignment = None\n",
    "        df = pd.read_csv(self.path_temperature(), parse_dates=['datetime'])\n",
    "        df = df[['datetime', 'Chicago']]\n",
    "        df.rename(columns={'Chicago': 'Temperature'}, inplace=True)\n",
    "        df = df[(self._start_year <= df['datetime']) & (df['datetime'] < self._end_year)]\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        df['hours'] = df['datetime'].dt.hour\n",
    "        df.drop(columns='datetime', inplace=True, axis=1)\n",
    "        return df\n",
    "\n",
    "    def df_sky(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.path_sky(), parse_dates=['datetime'])\n",
    "        df = df[['Chicago', 'datetime']]\n",
    "        df.dropna(inplace=True)\n",
    "        df = pd.get_dummies(df, columns=['Chicago'])\n",
    "        df = df[(self._start_year <= df['datetime']) & (df['datetime'] < self._end_year)]\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        df['hours'] = df['datetime'].dt.hour\n",
    "        df.drop(columns='datetime', inplace=True, axis=1)\n",
    "        return df\n",
    "\n",
    "    def df_merged(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        column_name = json.loads(open(self.path_columns()).read())\n",
    "        df_crime = pd.read_csv(self.path_crime(), sep=';')\n",
    "        df_crime.rename(columns=column_name['DataCrimes'], inplace=True)\n",
    "        df_socio = self.df_socio()\n",
    "        df_merged = pd.merge(df_crime, df_socio, on='community_area_number', how='left')\n",
    "        return df_merged\n",
    "\n",
    "    def df_crime_socio(self):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param year:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        df_crime = self.df_crime()\n",
    "        df_socio = self.df_socio()\n",
    "        df_crime = df_crime[(self._start_year <= df_crime['date']) & (df_crime['date'] < self._end_year)]\n",
    "        df_src = pd.merge(df_crime, df_socio, on='community_area_number', how='left')\n",
    "        del df_crime\n",
    "        del df_socio\n",
    "        return df_src\n",
    "\n",
    "    def df_nb_crimes(self):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param year:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        df_S = self.df_socio()\n",
    "        df_C = self.df_crime()\n",
    "        df_C = df_C[df_C.primary_type.isin(self._config[\"NameCrime\"])]\n",
    "        list_name_crimes = list(df_C['primary_type'].unique())\n",
    "        df_year = df_C[(self._start_year <= df_C['date']) & (df_C['date'] < self._end_year)]\n",
    "        df_year['month'] = pd.DatetimeIndex(df_year['date']).month\n",
    "        df_year['year'] = pd.DatetimeIndex(df_year['date']).year\n",
    "        df_year_grouped = df_year.groupby(['community_area_number', 'month', 'year', 'primary_type'],\n",
    "                                          as_index=False).agg({'id': 'count'})\n",
    "        df_year_grouped.rename(columns={'id': 'nb_crimes'}, inplace=True)\n",
    "        df_merged = pd.merge(df_year_grouped, df_S, on='community_area_number', how='inner')\n",
    "        del df_C\n",
    "        del df_S\n",
    "        df_merged.dropna(inplace=True)\n",
    "        df_merged.drop(['year', 'community_area_number'], axis=1, inplace=True)\n",
    "        df_merged_ = pd.get_dummies(df_merged, columns=['primary_type', 'community_area_name', 'month'])\n",
    "        del df_year_grouped\n",
    "        del df_merged\n",
    "        for col in list_name_crimes:\n",
    "            if \"primary_type_\" + col not in list(df_merged_.columns):\n",
    "                df_merged_[\"primary_type_\" + col] = -1\n",
    "        return df_merged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
